This test is a simple demo of ADMM using the openBuildNet simulation framework. There is one ADMM master node and 5 ADMM slave nodes.  The master node is updated regularly every 1000 time units (1 sec).  Everytime it is updated, it will start a new ADMM loop by communicating with the slaves to carry out the distributed computations.  In each iteration, the master node sends the mean x vector to all slaves, which will update their states and send back their x vector.  To model the time delay of communication and computation, the master node uses irregular updates to schedule the time points of the ADMM iterations.  The durations are randomly chosen between 5 and 40 time units.

A slave node listens to messages from the master node.  As soon as it receives a new message, it will extract the mean x vector, updates its states, and sends its new x vector to the master node.  A slave node is also a normal node in the simulation network.  To make the demo more interesting, every 1000 time units, each slave node will change its reference vector, causing the optimal solution to change.

The master dumps the values of the mean x vector over time to a tab-separated log file "admm.txt". It also plots the values using gnuplot.

To run the demo:
- Requires YARP network: start yarpserver.
- Build the entire project.
- Run the master node: ./nodeadmm
- Run 5 slave nodes with ID from 0 to 4:
      ./nodeslave 0
      ./nodeslave 1
      ./nodeslave 2
      ./nodeslave 3
      ./nodeslave 4
- Run the SMN: ./smntest3
- If gnuplot is available, after the simulation finishes, gnuplot will be called by nodeadmm to plot the results; press ENTER to close the plot window and exit.
